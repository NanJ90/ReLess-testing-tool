{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs: Time since first diagnosis</th>\n",
       "      <th>STDs: Time since last diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>18</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>34</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>52</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>46</td>\n",
       "      <td>3.0</td>\n",
       "      <td>21.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Age  Number of sexual partners  First sexual intercourse  \\\n",
       "0   18                        4.0                      15.0   \n",
       "1   15                        1.0                      14.0   \n",
       "2   34                        1.0                       NaN   \n",
       "3   52                        5.0                      16.0   \n",
       "4   46                        3.0                      21.0   \n",
       "\n",
       "   Num of pregnancies  Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "0                 1.0     0.0             0.0                  0.0   \n",
       "1                 1.0     0.0             0.0                  0.0   \n",
       "2                 1.0     0.0             0.0                  0.0   \n",
       "3                 4.0     1.0            37.0                 37.0   \n",
       "4                 4.0     0.0             0.0                  0.0   \n",
       "\n",
       "   Hormonal Contraceptives  Hormonal Contraceptives (years)  IUD  ...  \\\n",
       "0                      0.0                              0.0  0.0  ...   \n",
       "1                      0.0                              0.0  0.0  ...   \n",
       "2                      0.0                              0.0  0.0  ...   \n",
       "3                      1.0                              3.0  0.0  ...   \n",
       "4                      1.0                             15.0  0.0  ...   \n",
       "\n",
       "   STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n",
       "0                               NaN                              NaN   \n",
       "1                               NaN                              NaN   \n",
       "2                               NaN                              NaN   \n",
       "3                               NaN                              NaN   \n",
       "4                               NaN                              NaN   \n",
       "\n",
       "   Dx:Cancer  Dx:CIN  Dx:HPV  Dx  Hinselmann  Schiller  Citology  Biopsy  \n",
       "0          0       0       0   0           0         0         0       0  \n",
       "1          0       0       0   0           0         0         0       0  \n",
       "2          0       0       0   0           0         0         0       0  \n",
       "3          1       0       1   0           0         0         0       0  \n",
       "4          0       0       0   0           0         0         0       0  \n",
       "\n",
       "[5 rows x 36 columns]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/risk_factors_cervical_cancer.csv', na_values='?')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 858 entries, 0 to 857\n",
      "Data columns (total 36 columns):\n",
      " #   Column                              Non-Null Count  Dtype  \n",
      "---  ------                              --------------  -----  \n",
      " 0   Age                                 858 non-null    int64  \n",
      " 1   Number of sexual partners           832 non-null    float64\n",
      " 2   First sexual intercourse            851 non-null    float64\n",
      " 3   Num of pregnancies                  802 non-null    float64\n",
      " 4   Smokes                              845 non-null    float64\n",
      " 5   Smokes (years)                      845 non-null    float64\n",
      " 6   Smokes (packs/year)                 845 non-null    float64\n",
      " 7   Hormonal Contraceptives             750 non-null    float64\n",
      " 8   Hormonal Contraceptives (years)     750 non-null    float64\n",
      " 9   IUD                                 741 non-null    float64\n",
      " 10  IUD (years)                         741 non-null    float64\n",
      " 11  STDs                                753 non-null    float64\n",
      " 12  STDs (number)                       753 non-null    float64\n",
      " 13  STDs:condylomatosis                 753 non-null    float64\n",
      " 14  STDs:cervical condylomatosis        753 non-null    float64\n",
      " 15  STDs:vaginal condylomatosis         753 non-null    float64\n",
      " 16  STDs:vulvo-perineal condylomatosis  753 non-null    float64\n",
      " 17  STDs:syphilis                       753 non-null    float64\n",
      " 18  STDs:pelvic inflammatory disease    753 non-null    float64\n",
      " 19  STDs:genital herpes                 753 non-null    float64\n",
      " 20  STDs:molluscum contagiosum          753 non-null    float64\n",
      " 21  STDs:AIDS                           753 non-null    float64\n",
      " 22  STDs:HIV                            753 non-null    float64\n",
      " 23  STDs:Hepatitis B                    753 non-null    float64\n",
      " 24  STDs:HPV                            753 non-null    float64\n",
      " 25  STDs: Number of diagnosis           858 non-null    int64  \n",
      " 26  STDs: Time since first diagnosis    71 non-null     float64\n",
      " 27  STDs: Time since last diagnosis     71 non-null     float64\n",
      " 28  Dx:Cancer                           858 non-null    int64  \n",
      " 29  Dx:CIN                              858 non-null    int64  \n",
      " 30  Dx:HPV                              858 non-null    int64  \n",
      " 31  Dx                                  858 non-null    int64  \n",
      " 32  Hinselmann                          858 non-null    int64  \n",
      " 33  Schiller                            858 non-null    int64  \n",
      " 34  Citology                            858 non-null    int64  \n",
      " 35  Biopsy                              858 non-null    int64  \n",
      "dtypes: float64(26), int64(10)\n",
      "memory usage: 241.4 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Number of sexual partners</th>\n",
       "      <th>First sexual intercourse</th>\n",
       "      <th>Num of pregnancies</th>\n",
       "      <th>Smokes</th>\n",
       "      <th>Smokes (years)</th>\n",
       "      <th>Smokes (packs/year)</th>\n",
       "      <th>Hormonal Contraceptives</th>\n",
       "      <th>Hormonal Contraceptives (years)</th>\n",
       "      <th>IUD</th>\n",
       "      <th>...</th>\n",
       "      <th>STDs: Time since first diagnosis</th>\n",
       "      <th>STDs: Time since last diagnosis</th>\n",
       "      <th>Dx:Cancer</th>\n",
       "      <th>Dx:CIN</th>\n",
       "      <th>Dx:HPV</th>\n",
       "      <th>Dx</th>\n",
       "      <th>Hinselmann</th>\n",
       "      <th>Schiller</th>\n",
       "      <th>Citology</th>\n",
       "      <th>Biopsy</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>858.000000</td>\n",
       "      <td>832.000000</td>\n",
       "      <td>851.000000</td>\n",
       "      <td>802.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>845.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>750.000000</td>\n",
       "      <td>741.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>71.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "      <td>858.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>26.820513</td>\n",
       "      <td>2.527644</td>\n",
       "      <td>16.995300</td>\n",
       "      <td>2.275561</td>\n",
       "      <td>0.145562</td>\n",
       "      <td>1.219721</td>\n",
       "      <td>0.453144</td>\n",
       "      <td>0.641333</td>\n",
       "      <td>2.256419</td>\n",
       "      <td>0.112011</td>\n",
       "      <td>...</td>\n",
       "      <td>6.140845</td>\n",
       "      <td>5.816901</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.010490</td>\n",
       "      <td>0.020979</td>\n",
       "      <td>0.027972</td>\n",
       "      <td>0.040793</td>\n",
       "      <td>0.086247</td>\n",
       "      <td>0.051282</td>\n",
       "      <td>0.064103</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.497948</td>\n",
       "      <td>1.667760</td>\n",
       "      <td>2.803355</td>\n",
       "      <td>1.447414</td>\n",
       "      <td>0.352876</td>\n",
       "      <td>4.089017</td>\n",
       "      <td>2.226610</td>\n",
       "      <td>0.479929</td>\n",
       "      <td>3.764254</td>\n",
       "      <td>0.315593</td>\n",
       "      <td>...</td>\n",
       "      <td>5.895024</td>\n",
       "      <td>5.755271</td>\n",
       "      <td>0.143398</td>\n",
       "      <td>0.101939</td>\n",
       "      <td>0.143398</td>\n",
       "      <td>0.164989</td>\n",
       "      <td>0.197925</td>\n",
       "      <td>0.280892</td>\n",
       "      <td>0.220701</td>\n",
       "      <td>0.245078</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>13.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>10.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>20.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>25.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>17.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>32.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>3.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>7.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>84.000000</td>\n",
       "      <td>28.000000</td>\n",
       "      <td>32.000000</td>\n",
       "      <td>11.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>30.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>...</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>22.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8 rows × 36 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "              Age  Number of sexual partners  First sexual intercourse  \\\n",
       "count  858.000000                 832.000000                851.000000   \n",
       "mean    26.820513                   2.527644                 16.995300   \n",
       "std      8.497948                   1.667760                  2.803355   \n",
       "min     13.000000                   1.000000                 10.000000   \n",
       "25%     20.000000                   2.000000                 15.000000   \n",
       "50%     25.000000                   2.000000                 17.000000   \n",
       "75%     32.000000                   3.000000                 18.000000   \n",
       "max     84.000000                  28.000000                 32.000000   \n",
       "\n",
       "       Num of pregnancies      Smokes  Smokes (years)  Smokes (packs/year)  \\\n",
       "count          802.000000  845.000000      845.000000           845.000000   \n",
       "mean             2.275561    0.145562        1.219721             0.453144   \n",
       "std              1.447414    0.352876        4.089017             2.226610   \n",
       "min              0.000000    0.000000        0.000000             0.000000   \n",
       "25%              1.000000    0.000000        0.000000             0.000000   \n",
       "50%              2.000000    0.000000        0.000000             0.000000   \n",
       "75%              3.000000    0.000000        0.000000             0.000000   \n",
       "max             11.000000    1.000000       37.000000            37.000000   \n",
       "\n",
       "       Hormonal Contraceptives  Hormonal Contraceptives (years)         IUD  \\\n",
       "count               750.000000                       750.000000  741.000000   \n",
       "mean                  0.641333                         2.256419    0.112011   \n",
       "std                   0.479929                         3.764254    0.315593   \n",
       "min                   0.000000                         0.000000    0.000000   \n",
       "25%                   0.000000                         0.000000    0.000000   \n",
       "50%                   1.000000                         0.500000    0.000000   \n",
       "75%                   1.000000                         3.000000    0.000000   \n",
       "max                   1.000000                        30.000000    1.000000   \n",
       "\n",
       "       ...  STDs: Time since first diagnosis  STDs: Time since last diagnosis  \\\n",
       "count  ...                         71.000000                        71.000000   \n",
       "mean   ...                          6.140845                         5.816901   \n",
       "std    ...                          5.895024                         5.755271   \n",
       "min    ...                          1.000000                         1.000000   \n",
       "25%    ...                          2.000000                         2.000000   \n",
       "50%    ...                          4.000000                         3.000000   \n",
       "75%    ...                          8.000000                         7.500000   \n",
       "max    ...                         22.000000                        22.000000   \n",
       "\n",
       "        Dx:Cancer      Dx:CIN      Dx:HPV          Dx  Hinselmann    Schiller  \\\n",
       "count  858.000000  858.000000  858.000000  858.000000  858.000000  858.000000   \n",
       "mean     0.020979    0.010490    0.020979    0.027972    0.040793    0.086247   \n",
       "std      0.143398    0.101939    0.143398    0.164989    0.197925    0.280892   \n",
       "min      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "25%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "50%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "75%      0.000000    0.000000    0.000000    0.000000    0.000000    0.000000   \n",
       "max      1.000000    1.000000    1.000000    1.000000    1.000000    1.000000   \n",
       "\n",
       "         Citology      Biopsy  \n",
       "count  858.000000  858.000000  \n",
       "mean     0.051282    0.064103  \n",
       "std      0.220701    0.245078  \n",
       "min      0.000000    0.000000  \n",
       "25%      0.000000    0.000000  \n",
       "50%      0.000000    0.000000  \n",
       "75%      0.000000    0.000000  \n",
       "max      1.000000    1.000000  \n",
       "\n",
       "[8 rows x 36 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## checking missing value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "There are 3622 missing values in the dataset total of 30888 values\n",
      "Age                                     0\n",
      "Number of sexual partners              26\n",
      "First sexual intercourse                7\n",
      "Num of pregnancies                     56\n",
      "Smokes                                 13\n",
      "Smokes (years)                         13\n",
      "Smokes (packs/year)                    13\n",
      "Hormonal Contraceptives               108\n",
      "Hormonal Contraceptives (years)       108\n",
      "IUD                                   117\n",
      "IUD (years)                           117\n",
      "STDs                                  105\n",
      "STDs (number)                         105\n",
      "STDs:condylomatosis                   105\n",
      "STDs:cervical condylomatosis          105\n",
      "STDs:vaginal condylomatosis           105\n",
      "STDs:vulvo-perineal condylomatosis    105\n",
      "STDs:syphilis                         105\n",
      "STDs:pelvic inflammatory disease      105\n",
      "STDs:genital herpes                   105\n",
      "STDs:molluscum contagiosum            105\n",
      "STDs:AIDS                             105\n",
      "STDs:HIV                              105\n",
      "STDs:Hepatitis B                      105\n",
      "STDs:HPV                              105\n",
      "STDs: Number of diagnosis               0\n",
      "STDs: Time since first diagnosis      787\n",
      "STDs: Time since last diagnosis       787\n",
      "Dx:Cancer                               0\n",
      "Dx:CIN                                  0\n",
      "Dx:HPV                                  0\n",
      "Dx                                      0\n",
      "Hinselmann                              0\n",
      "Schiller                                0\n",
      "Citology                                0\n",
      "Biopsy                                  0\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(f'There are {df.isna().sum().sum()} missing values in the dataset total of {df.size} values')\n",
    "print(df.isna().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deleting missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping columns with more than 50% missing values, there are 2048 missing values in the dataset total of 29172 values\n"
     ]
    }
   ],
   "source": [
    "# Drop columns with more than 50% missing values\n",
    "df = df.dropna(thresh=0.5*len(df), axis=1)\n",
    "print(f'After dropping columns with more than 50% missing values, there are {df.isna().sum().sum()} missing values in the dataset total of {df.size} values')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After dropping rows with missing values, there are 0 missing values in the dataset total of 28314 values\n"
     ]
    }
   ],
   "source": [
    "# Drop rows with missing values\n",
    "df = df.dropna()    \n",
    "print(f'After dropping rows with missing values, there are {df.isna().sum().sum()} missing values in the dataset total of {X.size} values')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## separating features and target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Classifier: Mean Interpretability Score: 0.8125562543675752, std: 0.028958994843028336\n",
      "SVM Classifier: Mean Interpretability Score: 0.89715786163522, std: 0.02693790419689429\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "# Custom function to evaluate interpretability for Decision Trees\n",
    "def custom_interpretability_score(tree_model, X, y):\n",
    "    # Calculate accuracy\n",
    "    y_pred = tree_model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    \n",
    "    # Calculate complexity (using tree depth as a proxy for interpretability)\n",
    "    complexity = tree_model.get_depth()\n",
    "    \n",
    "    # Combine accuracy and complexity into a custom score\n",
    "    interpretability_score = accuracy - 0.01 * complexity  # Adjust the 0.01 weight as needed\n",
    "    \n",
    "    return interpretability_score\n",
    "\n",
    "# Custom function to evaluate interpretability for SVM\n",
    "def svm_interpretability_score(svm_model, X, y):\n",
    "    # Calculate accuracy\n",
    "    y_pred = svm_model.predict(X)\n",
    "    accuracy = accuracy_score(y, y_pred)\n",
    "    \n",
    "    # Calculate complexity (using number of support vectors as a proxy)\n",
    "    complexity = len(svm_model.support_)\n",
    "    \n",
    "    # Combine accuracy and complexity into a custom score\n",
    "    interpretability_score = accuracy - 0.001 * complexity  # Adjust the weight as needed\n",
    "    \n",
    "    return interpretability_score\n",
    "\n",
    "# Prepare data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Initialize models\n",
    "clf_dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "svm = SVC(kernel='linear', random_state=42)  # Using linear kernel for simplicity\n",
    "\n",
    "# Cross-validation setup\n",
    "kf = KFold(n_splits=10)\n",
    "\n",
    "# Evaluate Decision Tree with cross-validation\n",
    "interpretability_scores_dt = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold = X_train[train_index] if isinstance(X_train, np.ndarray) else X_train.iloc[train_index]\n",
    "    X_test_fold = X_train[test_index] if isinstance(X_train, np.ndarray) else X_train.iloc[test_index]\n",
    "    y_train_fold = y_train[train_index] if isinstance(y_train, np.ndarray) else y_train.iloc[train_index]\n",
    "    y_test_fold = y_train[test_index] if isinstance(y_train, np.ndarray) else y_train.iloc[test_index]\n",
    "    \n",
    "    clf_dt.fit(X_train_fold, y_train_fold)\n",
    "    score = custom_interpretability_score(clf_dt, X_test_fold, y_test_fold)\n",
    "    interpretability_scores_dt.append(score)\n",
    "\n",
    "mean_interpretability_score_dt = np.mean(interpretability_scores_dt)\n",
    "std_interpretability_score_dt = np.std(interpretability_scores_dt)\n",
    "\n",
    "print(f'Decision Tree Classifier: Mean Interpretability Score: {mean_interpretability_score_dt}, std: {std_interpretability_score_dt}')\n",
    "\n",
    "# Evaluate SVM with cross-validation\n",
    "interpretability_scores_svm = []\n",
    "\n",
    "for train_index, test_index in kf.split(X_train):\n",
    "    X_train_fold = X_train[train_index] if isinstance(X_train, np.ndarray) else X_train.iloc[train_index]\n",
    "    X_test_fold = X_train[test_index] if isinstance(X_train, np.ndarray) else X_train.iloc[test_index]\n",
    "    y_train_fold = y_train[train_index] if isinstance(y_train, np.ndarray) else y_train.iloc[train_index]\n",
    "    y_test_fold = y_train[test_index] if isinstance(y_train, np.ndarray) else y_train.iloc[test_index]\n",
    "    \n",
    "    svm.fit(X_train_fold, y_train_fold)\n",
    "    score = svm_interpretability_score(svm, X_test_fold, y_test_fold)\n",
    "    interpretability_scores_svm.append(score)\n",
    "\n",
    "mean_interpretability_score_svm = np.mean(interpretability_scores_svm)\n",
    "std_interpretability_score_svm = np.std(interpretability_scores_svm)\n",
    "\n",
    "print(f'SVM Classifier: Mean Interpretability Score: {mean_interpretability_score_svm}, std: {std_interpretability_score_svm}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 0s 7ms/step - loss: 0.6968 - accuracy: 0.5238 - val_loss: 0.6993 - val_accuracy: 0.4850\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6943 - accuracy: 0.5188 - val_loss: 0.6992 - val_accuracy: 0.5000\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 6ms/step - loss: 0.6915 - accuracy: 0.5175 - val_loss: 0.6981 - val_accuracy: 0.5000\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6902 - accuracy: 0.5362 - val_loss: 0.6969 - val_accuracy: 0.4850\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6886 - accuracy: 0.5350 - val_loss: 0.6971 - val_accuracy: 0.5050\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6871 - accuracy: 0.5500 - val_loss: 0.6978 - val_accuracy: 0.4950\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6861 - accuracy: 0.5525 - val_loss: 0.6976 - val_accuracy: 0.4800\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6868 - accuracy: 0.5300 - val_loss: 0.6967 - val_accuracy: 0.4850\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6858 - accuracy: 0.5450 - val_loss: 0.6962 - val_accuracy: 0.4800\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6832 - accuracy: 0.5587 - val_loss: 0.6945 - val_accuracy: 0.4950\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6808 - accuracy: 0.5625 - val_loss: 0.6957 - val_accuracy: 0.4900\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6793 - accuracy: 0.5688 - val_loss: 0.6950 - val_accuracy: 0.4800\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6780 - accuracy: 0.5775 - val_loss: 0.6946 - val_accuracy: 0.4750\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6769 - accuracy: 0.5850 - val_loss: 0.6951 - val_accuracy: 0.4850\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6771 - accuracy: 0.5813 - val_loss: 0.6960 - val_accuracy: 0.4900\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6754 - accuracy: 0.5775 - val_loss: 0.6939 - val_accuracy: 0.4800\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 1ms/step - loss: 0.6742 - accuracy: 0.5750 - val_loss: 0.6937 - val_accuracy: 0.5000\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6732 - accuracy: 0.5938 - val_loss: 0.6939 - val_accuracy: 0.4950\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.6000 - val_loss: 0.6939 - val_accuracy: 0.4850\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6703 - accuracy: 0.6012 - val_loss: 0.6939 - val_accuracy: 0.5150\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6700 - accuracy: 0.5975 - val_loss: 0.6938 - val_accuracy: 0.5200\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6679 - accuracy: 0.6050 - val_loss: 0.6946 - val_accuracy: 0.4900\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6657 - accuracy: 0.6050 - val_loss: 0.6930 - val_accuracy: 0.5200\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6657 - accuracy: 0.6025 - val_loss: 0.6951 - val_accuracy: 0.4950\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6645 - accuracy: 0.6150 - val_loss: 0.6938 - val_accuracy: 0.5100\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6212 - val_loss: 0.6929 - val_accuracy: 0.5200\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6607 - accuracy: 0.6150 - val_loss: 0.6927 - val_accuracy: 0.5400\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6617 - accuracy: 0.6237 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6580 - accuracy: 0.6200 - val_loss: 0.6931 - val_accuracy: 0.5250\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6575 - accuracy: 0.6388 - val_loss: 0.6930 - val_accuracy: 0.5350\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6557 - accuracy: 0.6275 - val_loss: 0.6920 - val_accuracy: 0.5550\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6550 - accuracy: 0.6300 - val_loss: 0.6951 - val_accuracy: 0.5150\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6533 - accuracy: 0.6463 - val_loss: 0.6911 - val_accuracy: 0.5300\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6511 - accuracy: 0.6525 - val_loss: 0.6914 - val_accuracy: 0.5250\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6485 - accuracy: 0.6513 - val_loss: 0.6939 - val_accuracy: 0.5250\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6482 - accuracy: 0.6413 - val_loss: 0.6917 - val_accuracy: 0.5400\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6473 - accuracy: 0.6375 - val_loss: 0.6933 - val_accuracy: 0.5350\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6461 - accuracy: 0.6450 - val_loss: 0.6956 - val_accuracy: 0.5250\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6437 - accuracy: 0.6550 - val_loss: 0.6913 - val_accuracy: 0.5400\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6675 - val_loss: 0.6927 - val_accuracy: 0.5200\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6440 - accuracy: 0.6500 - val_loss: 0.6925 - val_accuracy: 0.5550\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6405 - accuracy: 0.6500 - val_loss: 0.6923 - val_accuracy: 0.5250\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6376 - accuracy: 0.6662 - val_loss: 0.6922 - val_accuracy: 0.5200\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6361 - accuracy: 0.6575 - val_loss: 0.6931 - val_accuracy: 0.5400\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6362 - accuracy: 0.6700 - val_loss: 0.6953 - val_accuracy: 0.5350\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6352 - accuracy: 0.6625 - val_loss: 0.6913 - val_accuracy: 0.5500\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6314 - accuracy: 0.6800 - val_loss: 0.6935 - val_accuracy: 0.5300\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6303 - accuracy: 0.6775 - val_loss: 0.6952 - val_accuracy: 0.5300\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6293 - accuracy: 0.6675 - val_loss: 0.6922 - val_accuracy: 0.5350\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6295 - accuracy: 0.6712 - val_loss: 0.6925 - val_accuracy: 0.5450\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6393 - accuracy: 0.6410\n",
      "Standard Deviation: 0.20613035559654236\n",
      "Loss: 0.63933926820755, Accuracy: 0.640999972820282\n",
      "You must install pydot (`pip install pydot`) and install graphviz (see instructions at https://graphviz.gitlab.io/download/) for plot_model to work.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "# Example data\n",
    "# Replace this with your actual dataset\n",
    "X_train = np.random.rand(1000, 20)  # 1000 samples, 20 features\n",
    "y_train = np.random.randint(2, size=(1000, 1))  # 1000 samples, binary classification\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(49, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss, accuracy = model.evaluate(X_train, y_train)\n",
    "\n",
    "# Flatten all weight arrays into a single array\n",
    "weights = np.concatenate([w.flatten() for w in model.get_weights()])\n",
    "\n",
    "# Calculate the standard deviation of the flattened weight array\n",
    "std = np.std(weights)\n",
    "print(f\"Standard Deviation: {std}\")\n",
    "print(f\"Loss: {loss}, Accuracy: {accuracy}\")\n",
    "\n",
    "#visualize the model\n",
    "from tensorflow.keras.utils import plot_model\n",
    "plot_model(model, to_file='model_plot.png', show_shapes=True, show_layer_names=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "25/25 [==============================] - 0s 5ms/step - loss: 0.7042 - accuracy: 0.5113 - val_loss: 0.6987 - val_accuracy: 0.5100\n",
      "Epoch 2/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6971 - accuracy: 0.5013 - val_loss: 0.6996 - val_accuracy: 0.4950\n",
      "Epoch 3/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6933 - accuracy: 0.5288 - val_loss: 0.6965 - val_accuracy: 0.5100\n",
      "Epoch 4/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6911 - accuracy: 0.5350 - val_loss: 0.6992 - val_accuracy: 0.4750\n",
      "Epoch 5/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6892 - accuracy: 0.5375 - val_loss: 0.6991 - val_accuracy: 0.4800\n",
      "Epoch 6/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6876 - accuracy: 0.5512 - val_loss: 0.6990 - val_accuracy: 0.4800\n",
      "Epoch 7/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6861 - accuracy: 0.5500 - val_loss: 0.6957 - val_accuracy: 0.5050\n",
      "Epoch 8/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6857 - accuracy: 0.5450 - val_loss: 0.6961 - val_accuracy: 0.5000\n",
      "Epoch 9/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6832 - accuracy: 0.5475 - val_loss: 0.6978 - val_accuracy: 0.5200\n",
      "Epoch 10/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6824 - accuracy: 0.5512 - val_loss: 0.6969 - val_accuracy: 0.4900\n",
      "Epoch 11/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6810 - accuracy: 0.5550 - val_loss: 0.6987 - val_accuracy: 0.4900\n",
      "Epoch 12/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6808 - accuracy: 0.5562 - val_loss: 0.6960 - val_accuracy: 0.5150\n",
      "Epoch 13/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6795 - accuracy: 0.5763 - val_loss: 0.6971 - val_accuracy: 0.5100\n",
      "Epoch 14/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6783 - accuracy: 0.5638 - val_loss: 0.6981 - val_accuracy: 0.5150\n",
      "Epoch 15/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6773 - accuracy: 0.5713 - val_loss: 0.6974 - val_accuracy: 0.5200\n",
      "Epoch 16/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6761 - accuracy: 0.5788 - val_loss: 0.7000 - val_accuracy: 0.4900\n",
      "Epoch 17/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6750 - accuracy: 0.5788 - val_loss: 0.6982 - val_accuracy: 0.5150\n",
      "Epoch 18/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5888 - val_loss: 0.6997 - val_accuracy: 0.4950\n",
      "Epoch 19/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6747 - accuracy: 0.5813 - val_loss: 0.6982 - val_accuracy: 0.5350\n",
      "Epoch 20/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6721 - accuracy: 0.5863 - val_loss: 0.6997 - val_accuracy: 0.5100\n",
      "Epoch 21/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6718 - accuracy: 0.5900 - val_loss: 0.6993 - val_accuracy: 0.5300\n",
      "Epoch 22/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6713 - accuracy: 0.5913 - val_loss: 0.7014 - val_accuracy: 0.5050\n",
      "Epoch 23/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6698 - accuracy: 0.5900 - val_loss: 0.6989 - val_accuracy: 0.5300\n",
      "Epoch 24/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6692 - accuracy: 0.5938 - val_loss: 0.7030 - val_accuracy: 0.4900\n",
      "Epoch 25/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6742 - accuracy: 0.5550 - val_loss: 0.7001 - val_accuracy: 0.5500\n",
      "Epoch 26/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6711 - accuracy: 0.5788 - val_loss: 0.7044 - val_accuracy: 0.4950\n",
      "Epoch 27/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6680 - accuracy: 0.5900 - val_loss: 0.7024 - val_accuracy: 0.5100\n",
      "Epoch 28/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6656 - accuracy: 0.5962 - val_loss: 0.7009 - val_accuracy: 0.5300\n",
      "Epoch 29/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6648 - accuracy: 0.5962 - val_loss: 0.7027 - val_accuracy: 0.5000\n",
      "Epoch 30/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6643 - accuracy: 0.5950 - val_loss: 0.7018 - val_accuracy: 0.5200\n",
      "Epoch 31/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6629 - accuracy: 0.5987 - val_loss: 0.7023 - val_accuracy: 0.5150\n",
      "Epoch 32/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6632 - accuracy: 0.6025 - val_loss: 0.7019 - val_accuracy: 0.5150\n",
      "Epoch 33/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6619 - accuracy: 0.6162 - val_loss: 0.7045 - val_accuracy: 0.5050\n",
      "Epoch 34/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6597 - accuracy: 0.6125 - val_loss: 0.7018 - val_accuracy: 0.5550\n",
      "Epoch 35/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6586 - accuracy: 0.6000 - val_loss: 0.7047 - val_accuracy: 0.4950\n",
      "Epoch 36/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6572 - accuracy: 0.6062 - val_loss: 0.7031 - val_accuracy: 0.5500\n",
      "Epoch 37/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6562 - accuracy: 0.6237 - val_loss: 0.7051 - val_accuracy: 0.5000\n",
      "Epoch 38/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6552 - accuracy: 0.6200 - val_loss: 0.7057 - val_accuracy: 0.5050\n",
      "Epoch 39/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6545 - accuracy: 0.6137 - val_loss: 0.7033 - val_accuracy: 0.5450\n",
      "Epoch 40/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6550 - accuracy: 0.6175 - val_loss: 0.7067 - val_accuracy: 0.5200\n",
      "Epoch 41/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6522 - accuracy: 0.6225 - val_loss: 0.7054 - val_accuracy: 0.5400\n",
      "Epoch 42/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6529 - accuracy: 0.6225 - val_loss: 0.7122 - val_accuracy: 0.5100\n",
      "Epoch 43/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6530 - accuracy: 0.6050 - val_loss: 0.7074 - val_accuracy: 0.5200\n",
      "Epoch 44/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6498 - accuracy: 0.6237 - val_loss: 0.7074 - val_accuracy: 0.5150\n",
      "Epoch 45/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6512 - accuracy: 0.6187 - val_loss: 0.7135 - val_accuracy: 0.5000\n",
      "Epoch 46/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6483 - accuracy: 0.6350 - val_loss: 0.7075 - val_accuracy: 0.5450\n",
      "Epoch 47/50\n",
      "25/25 [==============================] - 0s 3ms/step - loss: 0.6454 - accuracy: 0.6325 - val_loss: 0.7071 - val_accuracy: 0.5400\n",
      "Epoch 48/50\n",
      "25/25 [==============================] - 0s 4ms/step - loss: 0.6444 - accuracy: 0.6300 - val_loss: 0.7092 - val_accuracy: 0.5450\n",
      "Epoch 49/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6432 - accuracy: 0.6250 - val_loss: 0.7087 - val_accuracy: 0.5400\n",
      "Epoch 50/50\n",
      "25/25 [==============================] - 0s 2ms/step - loss: 0.6422 - accuracy: 0.6363 - val_loss: 0.7078 - val_accuracy: 0.5250\n",
      "32/32 [==============================] - 0s 836us/step - loss: 0.6518 - accuracy: 0.6180\n",
      "Loss before removal: 0.6518480777740479, Accuracy before removal: 0.6179999709129333\n",
      "32/32 [==============================] - 0s 1ms/step - loss: 0.6518 - accuracy: 0.6180\n",
      "Loss after removal: 0.6518480777740479, Accuracy after removal: 0.6179999709129333\n",
      "Jaccard similarity index: 1.0\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.metrics import jaccard_score\n",
    "\n",
    "# Example data\n",
    "# Replace this with your actual dataset\n",
    "X_train = np.random.rand(1000, 20)  # 1000 samples, 20 features\n",
    "y_train = np.random.randint(2, size=(1000, 1))  # 1000 samples, binary classification\n",
    "\n",
    "# Convert labels to one-hot encoding\n",
    "y_train = tf.keras.utils.to_categorical(y_train, num_classes=2)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(49, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model\n",
    "loss_before, accuracy_before = model.evaluate(X_train, y_train)\n",
    "print(f\"Loss before removal: {loss_before}, Accuracy before removal: {accuracy_before}\")\n",
    "\n",
    "# Function to apply CM-RIE algorithm to remove irrelevant edges\n",
    "def cm_rie(weights, class_label):\n",
    "    tempD = []\n",
    "    tempCount = 0\n",
    "    D = weights.copy()\n",
    "\n",
    "    for i in range(len(D)):\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        if D[i][class_label] == 0:\n",
    "            for j in range(len(D[i])):\n",
    "                if j != class_label:\n",
    "                    if D[i][j] != 0:\n",
    "                        temp1.append(D[i][j])\n",
    "                        temp2.append(j)\n",
    "            if class_label == 0:\n",
    "                D[i][1] = np.mean(temp1)\n",
    "            else:\n",
    "                D[i][0] = np.mean(temp1)\n",
    "            for k in temp2:\n",
    "                D[i][k] = 0\n",
    "            tempD.append(i)\n",
    "\n",
    "    if class_label == 0:\n",
    "        negative_node = 1\n",
    "    else:\n",
    "        negative_node = 0\n",
    "\n",
    "    if len(tempD) > 1:\n",
    "        for i in tempD:\n",
    "            if class_label == 0:\n",
    "                tempCount += D[i][1]\n",
    "            else:\n",
    "                tempCount += D[i][0]\n",
    "\n",
    "        D[tempD[0]][negative_node] = np.mean(tempCount)\n",
    "        for x in tempD[1:]:\n",
    "            D[x][negative_node] = 0\n",
    "\n",
    "        for i in range(len(D)):\n",
    "            tempDL = []\n",
    "            for j in tempD:\n",
    "                tempDL.append(D[i][j])\n",
    "            D[i][tempD[0]] = np.mean(tempDL)\n",
    "\n",
    "        for x in tempD[1:]:\n",
    "            for y in range(len(D)):\n",
    "                D[y][x] = 0\n",
    "\n",
    "    return D\n",
    "\n",
    "# Retrieve weights from the trained model\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Save original weights and biases as 1-D arrays\n",
    "original_weights_flattened = np.concatenate([w.flatten() for w in weights])\n",
    "\n",
    "# Apply CM-RIE algorithm to the first layer's weights (hidden layer)\n",
    "updated_weights = cm_rie(weights[0], 0)\n",
    "\n",
    "# Update the model's weights\n",
    "weights[0] = updated_weights\n",
    "model.set_weights(weights)\n",
    "\n",
    "# Re-evaluate the model to see the effect of removing irrelevant edges\n",
    "loss_after, accuracy_after = model.evaluate(X_train, y_train)\n",
    "print(f\"Loss after removal: {loss_after}, Accuracy after removal: {accuracy_after}\")\n",
    "\n",
    "# Save updated weights and biases as 1-D arrays\n",
    "updated_weights_flattened = np.concatenate([w.flatten() for w in model.get_weights()])\n",
    "\n",
    "# Calculate Jaccard similarity index\n",
    "jaccard_similarity = jaccard_score(original_weights_flattened != 0, updated_weights_flattened != 0)\n",
    "print(f\"Jaccard similarity index: {jaccard_similarity}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import each models' h5 \n",
    "import h5py\n",
    "import os\n",
    "from tqdm import tqdm\n",
    "import glob\n",
    "import importlib\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "import sys\n",
    "sys.path.append('../modularity/remove_irrelavant_edges/MNIST-1/utils/')\n",
    "from mnistutil import MNISTUitl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (60000, 28, 28, 1)\n",
      "(60000, 28, 28, 1) 60000 train samples (60000,)\n",
      "10000 test samples\n",
      "(60000,) (60000,)\n"
     ]
    }
   ],
   "source": [
    "# In[]: Data Load\n",
    "labs = [0,1,2,3,4,5,6,7,8,9]\n",
    "sx = 28\n",
    "sy = 28\n",
    "mn = MNISTUitl()\n",
    "X, Y, x, y = mn.getdata2(0,0,sx,sy)\n",
    "#nm , xt, yt = mn.train2(X, Y, x,y,sx,sy,10,50)\n",
    "xt, yt, xT, yT = mn.trainData(X, Y, x,y,sx,sy,10,50)# test x,y, and train x,y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Decision Tree Training Accuracy: 1.0\n",
      "SVM Training Accuracy: 0.7535666666666667\n",
      "Decision Tree Test Accuracy: 0.8856\n",
      "SVM Test Accuracy: 0.7649\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Assuming xt, yt, xT, yT are provided as numpy arrays or pandas DataFrames\n",
    "# If they are DataFrames, convert them to numpy arrays\n",
    "if isinstance(xt, pd.DataFrame):\n",
    "    xt = xt.values\n",
    "if isinstance(yt, pd.DataFrame):\n",
    "    yt = yt.values\n",
    "if isinstance(xT, pd.DataFrame):\n",
    "    xT = xT.values\n",
    "if isinstance(yT, pd.DataFrame):\n",
    "    yT = yT.values\n",
    "\n",
    "# Reshape the data\n",
    "xt_flat = xt.reshape(xt.shape[0], -1)  # Flatten each image into a vector\n",
    "xT_flat = xT.reshape(xT.shape[0], -1)  # Flatten each image into a vector\n",
    "\n",
    "# Initialize models\n",
    "clf_dt = DecisionTreeClassifier(criterion='entropy', random_state=42)\n",
    "svm = SVC(kernel='linear', random_state=42)  # Using linear kernel for simplicity\n",
    "\n",
    "# Fit the models\n",
    "clf_dt.fit(xT_flat, yT)\n",
    "svm.fit(xT_flat, yT)\n",
    "\n",
    "# Evaluate the models on the training set\n",
    "y_train_pred_dt = clf_dt.predict(xT_flat)\n",
    "y_train_pred_svm = svm.predict(xT_flat)\n",
    "\n",
    "accuracy_train_dt = accuracy_score(yT, y_train_pred_dt)\n",
    "accuracy_train_svm = accuracy_score(yT, y_train_pred_svm)\n",
    "\n",
    "print(f\"Decision Tree Training Accuracy: {accuracy_train_dt}\")\n",
    "print(f\"SVM Training Accuracy: {accuracy_train_svm}\")\n",
    "\n",
    "# Evaluate the models on the test set\n",
    "y_test_pred_dt = clf_dt.predict(xt_flat)\n",
    "y_test_pred_svm = svm.predict(xt_flat)\n",
    "\n",
    "accuracy_test_dt = accuracy_score(yt, y_test_pred_dt)\n",
    "accuracy_test_svm = accuracy_score(yt, y_test_pred_svm)\n",
    "\n",
    "print(f\"Decision Tree Test Accuracy: {accuracy_test_dt}\")\n",
    "print(f\"SVM Test Accuracy: {accuracy_test_svm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "# Load the dataset\n",
    "df = pd.read_csv('../data/risk_factors_cervical_cancer.csv')\n",
    "\n",
    "# Preprocess the dataset\n",
    "df = df.replace('?', np.nan)\n",
    "df = df.dropna()\n",
    "\n",
    "# Convert target column to binary classification\n",
    "X = df.drop(columns=['Biopsy']).values\n",
    "y = df['Biopsy'].values\n",
    "y = tf.keras.utils.to_categorical(y, num_classes=2)\n",
    "\n",
    "# Split the dataset into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Standardize the data\n",
    "scaler = StandardScaler()\n",
    "X_train = scaler.fit_transform(X_train)\n",
    "X_test = scaler.transform(X_test)\n",
    "\n",
    "# Define the model\n",
    "model = Sequential()\n",
    "model.add(Dense(49, input_dim=X_train.shape[1], activation='relu'))  # Hidden layer\n",
    "model.add(Dense(2, activation='softmax'))  # Output layer\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, epochs=50, batch_size=32, validation_split=0.2)\n",
    "\n",
    "# Evaluate the model before removing irrelevant edges\n",
    "loss_before, accuracy_before = model.evaluate(X_train, y_train)\n",
    "print(f\"Loss before removal: {loss_before}, Accuracy before removal: {accuracy_before}\")\n",
    "\n",
    "# Function to apply CM-RIE algorithm to remove irrelevant edges\n",
    "def cm_rie(weights, class_label):\n",
    "    tempD = []\n",
    "    tempCount = 0\n",
    "    D = weights.copy()\n",
    "\n",
    "    for i in range(len(D)):\n",
    "        temp1 = []\n",
    "        temp2 = []\n",
    "        if D[i][class_label] == 0:\n",
    "            for j in range(len(D[i])):\n",
    "                if j != class_label:\n",
    "                    if D[i][j] != 0:\n",
    "                        temp1.append(D[i][j])\n",
    "                        temp2.append(j)\n",
    "            if class_label == 0:\n",
    "                D[i][1] = np.mean(temp1)\n",
    "            else:\n",
    "                D[i][0] = np.mean(temp1)\n",
    "            for k in temp2:\n",
    "                D[i][k] = 0\n",
    "            tempD.append(i)\n",
    "\n",
    "    if class_label == 0:\n",
    "        negative_node = 1\n",
    "    else:\n",
    "        negative_node = 0\n",
    "\n",
    "    if len(tempD) > 1:\n",
    "        for i in tempD:\n",
    "            if class_label == 0:\n",
    "                tempCount += D[i][1]\n",
    "            else:\n",
    "                tempCount += D[i][0]\n",
    "\n",
    "        D[tempD[0]][negative_node] = np.mean(tempCount)\n",
    "        for x in tempD[1:]:\n",
    "            D[x][negative_node] = 0\n",
    "\n",
    "        for i in range(len(D)):\n",
    "            tempDL = []\n",
    "            for j in tempD:\n",
    "                tempDL.append(D[i][j])\n",
    "            D[i][tempD[0]] = np.mean(tempDL)\n",
    "\n",
    "        for x in tempD[1:]:\n",
    "            for y in range(len(D)):\n",
    "                D[y][x] = 0\n",
    "\n",
    "    return D\n",
    "\n",
    "# Retrieve weights from the trained model\n",
    "weights = model.get_weights()\n",
    "\n",
    "# Apply CM-RIE algorithm to the first layer's weights (hidden layer)\n",
    "updated_weights = cm_rie(weights[0], 0)\n",
    "\n",
    "# Update the model's weights\n",
    "weights[0] = updated_weights\n",
    "model.set_weights(weights)\n",
    "\n",
    "# Evaluate the model after removing irrelevant edges\n",
    "loss_after, accuracy_after = model.evaluate(X_train, y_train)\n",
    "print(f\"Loss after removal: {loss_after}, Accuracy after removal: {accuracy_after}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "reless-python3.8",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
